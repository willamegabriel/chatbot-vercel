"use strict";
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// src/index.ts
var src_exports = {};
__export(src_exports, {
  DefaultEmbeddingFunction: () => DefaultEmbeddingFunction
});
module.exports = __toCommonJS(src_exports);
var import_ai_embeddings_common = require("@chroma-core/ai-embeddings-common");
var import_transformers = require("@huggingface/transformers");
var import_transformers2 = require("@huggingface/transformers");
var DefaultEmbeddingFunction = class _DefaultEmbeddingFunction {
  constructor(args = {}) {
    this.name = "default";
    this.progressCallback = void 0;
    const {
      modelName = "Xenova/all-MiniLM-L6-v2",
      revision = "main",
      dtype = void 0,
      progressCallback = void 0,
      quantized = false,
      wasm = false
    } = args;
    this.modelName = modelName;
    this.revision = revision;
    this.dtype = dtype || (quantized ? "uint8" : "fp32");
    this.quantized = quantized;
    this.progressCallback = progressCallback;
    this.wasm = wasm;
    if (this.wasm) {
      import_transformers2.env.backends.onnx.backend = "wasm";
    }
  }
  static buildFromConfig(config) {
    return new _DefaultEmbeddingFunction(config);
  }
  async generate(texts) {
    const pipe = await (0, import_transformers.pipeline)("feature-extraction", this.modelName, {
      revision: this.revision,
      progress_callback: this.progressCallback,
      dtype: this.dtype
    });
    const output = await pipe(texts, { pooling: "mean", normalize: true });
    return output.tolist();
  }
  defaultSpace() {
    return "cosine";
  }
  supportedSpaces() {
    return ["cosine", "l2", "ip"];
  }
  getConfig() {
    return {
      model_name: this.modelName,
      revision: this.revision,
      dtype: this.dtype,
      quantized: this.quantized
    };
  }
  validateConfigUpdate(newConfig) {
    if (this.getConfig().model_name !== newConfig.model_name) {
      throw new Error(
        "The DefaultEmbeddingFunction's 'model' cannot be changed after initialization."
      );
    }
  }
  static validateConfig(config) {
    (0, import_ai_embeddings_common.validateConfigSchema)(config, "transformers");
  }
};
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
  DefaultEmbeddingFunction
});
//# sourceMappingURL=default-embed.cjs.map