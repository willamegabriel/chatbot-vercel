// src/index.ts
import { validateConfigSchema } from "@chroma-core/ai-embeddings-common";
import { pipeline } from "@huggingface/transformers";
import { env as TransformersEnv } from "@huggingface/transformers";
var DefaultEmbeddingFunction = class _DefaultEmbeddingFunction {
  constructor(args = {}) {
    this.name = "default";
    this.progressCallback = void 0;
    const {
      modelName = "Xenova/all-MiniLM-L6-v2",
      revision = "main",
      dtype = void 0,
      progressCallback = void 0,
      quantized = false,
      wasm = false
    } = args;
    this.modelName = modelName;
    this.revision = revision;
    this.dtype = dtype || (quantized ? "uint8" : "fp32");
    this.quantized = quantized;
    this.progressCallback = progressCallback;
    this.wasm = wasm;
    if (this.wasm) {
      TransformersEnv.backends.onnx.backend = "wasm";
    }
  }
  static buildFromConfig(config) {
    return new _DefaultEmbeddingFunction(config);
  }
  async generate(texts) {
    const pipe = await pipeline("feature-extraction", this.modelName, {
      revision: this.revision,
      progress_callback: this.progressCallback,
      dtype: this.dtype
    });
    const output = await pipe(texts, { pooling: "mean", normalize: true });
    return output.tolist();
  }
  defaultSpace() {
    return "cosine";
  }
  supportedSpaces() {
    return ["cosine", "l2", "ip"];
  }
  getConfig() {
    return {
      model_name: this.modelName,
      revision: this.revision,
      dtype: this.dtype,
      quantized: this.quantized
    };
  }
  validateConfigUpdate(newConfig) {
    if (this.getConfig().model_name !== newConfig.model_name) {
      throw new Error(
        "The DefaultEmbeddingFunction's 'model' cannot be changed after initialization."
      );
    }
  }
  static validateConfig(config) {
    validateConfigSchema(config, "transformers");
  }
};
export {
  DefaultEmbeddingFunction
};
//# sourceMappingURL=default-embed.mjs.map